# Copyright (C) 2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

[tool.poetry]
name = "vlm-openvino-serving"
version = "0.1.0"
description = "FastAPI server wrapping OpenVINO runtime to serve `/chat/completion` endpoint to consume multimodal image input/video input and serve inference with VLM models."
authors = []
readme = "README.md"
package-mode = false

[tool.poetry.dependencies]
python = "^3.10,<3.13"
torch = { version = ">=2.7.1", source = "pytorch-cpu" }
torchvision = { version = ">=0.22.1", source = "pytorch-cpu" }
fastapi = "^0.115.12"
fastapi-utils = "^0.8.0"
typing-inspect = "^0.9.0"
uvicorn = "^0.34.2"
gunicorn = "^23.0.0"
pydantic = "^2.11.5"
pydantic-settings = "^2.9.1"
nncf = "^2.17.0"
transformers = "^4.51.3"
pillow = "^11.3.0"
openvino = "^2025.2.0"
openvino-tokenizers = "^2025.2.0.0"
openvino-genai = "^2025.2.0.0"
optimum-intel = "^1.23.0"
qwen_vl_utils = "^0.0.11"

[[tool.poetry.source]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
priority = "explicit"

[tool.poetry.group.test.dependencies]
pytest = "^8.3.5"
pytest-mock = "^3.14.1"
coverage = "^7.8.2"
pytest-asyncio = "^1.0.0"
httpx = "^0.28.1"

[tool.pytest.ini_options]
asyncio_default_fixture_loop_scope = "module"

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

