apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Values.ovms.script.name }}
  labels:
    app: {{ .Values.ovms.script.name }}

data:
  init-embed-script.sh: |-
    #!/bin/bash
    model=$0
    weight_format=$1
    gpu_enabled=$3
    # FLATTENED_MODEL_NAME=$(echo ${model} | tr '/' '-')
    pip3 install -r https://raw.githubusercontent.com/openvinotoolkit/model_server/refs/heads/releases/2025/3/demos/common/export_models/requirements.txt
    
    pip3 install -U huggingface_hub[hf_xet]

    # Log in to Hugging Face using the provided token
    hf auth login --token $2

    # Check if the login was successful
    if [ $? -eq 0 ]; then
        echo "Successfully logged in to Hugging Face!"
    else
        echo "Failed to log in to Hugging Face. Please check your token and try again."
    fi
    curl https://raw.githubusercontent.com/openvinotoolkit/model_server/refs/heads/releases/2025/3/demos/common/export_models/export_model.py -o export_model.py
    mkdir models
    if [ "$gpu_enabled" = "true" ]; then
        echo "GPU is enabled, using GPU model"
        python3 export_model.py embeddings_ov --source_model "${model}" --weight-format "${weight_format}" --config_file_path models/config.json  --model_repository_path models --target_device {{ .Values.global.gpu.device }}
    else
        echo "GPU is not enabled, using CPU model"
        python3 export_model.py embeddings_ov --source_model "${model}" --weight-format "${weight_format}" --config_file_path models/config.json  --model_repository_path models --target_device CPU
        
    fi

    cp -r models /opt/data/
    echo "All the steps are completed successfully"