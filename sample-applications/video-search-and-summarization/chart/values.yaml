global:
  # pvcName is the name of common PVC used by multiple microservices for persisting models, cache and other files.
  pvcName: ""
  # claimSize is the size of the PVC to be created.
  claimSize: "50Gi"  
  # keepPvc should be set to true to retain the PVC after uninstalling the chart.
  keepPvc: false

  # huggingfaceToken should be set during installation if gated models need to be accessed.
  huggingfaceToken: ""

  # vdmsIndexName is the DB Index or DB Collection name used by VDMS Vector DB.
  vdmsIndexName: ""

  # vlmName is Vision-Language Model Name used by VLM Inference Microservice
  vlmName: ""
  # llmName is Large Language Model Name used by OVMS service
  llmName: ""

  proxy:
    no_proxy: "localhost,127.0.0.1,192.168.0.0/16,172.16.0.0/12,127.0.0.0/8,10.0.0.0/8,.svc.cluster.local"
    http_proxy: ""
    https_proxy: ""
  env:
    POSTGRES_DB: video_summary_db
    POSTGRES_USER: ""
    POSTGRES_PASSWORD: ""
    MINIO_ROOT_USER: ""
    MINIO_ROOT_PASSWORD: ""
    RABBITMQ_DEFAULT_USER: ""
    RABBITMQ_DEFAULT_PASS: ""
    OTLP_ENDPOINT: ""
    OTLP_ENDPOINT_TRACE: ""
    keeppvc: false # Set to true to keep PVCs after uninstalling the chart

rabbitmq:
  enabled: false
  name: rabbitmq
  fullname: rabbitmq
  service:
    name: rabbitmq
    type: ClusterIP
    amqpPort: 5672
    managementPort: 15672
    mqttPort: 1883

minioserver:
  service:
    apiPort: 9000

videoSummaryManager:
  name: videosummarybackend
  image:
    repository: intel/pipeline-manager
    tag: "1.2.1"
    pullPolicy: IfNotPresent
  containerPortName: videosumm-port # Optional name to refer containerPort
  service:
    type: ClusterIP
    port: 80    # Port on which service listens for incoming connection, if exposed externally
  minioProtocol: "http:"
  minioBucket: "video-search-summary"
  env:
    LLM_SUMMARIZATION_KEY: ""
    LLM_SUMMARIZATION_DEVICE: "CPU"
    VLM_CAPTIONING_KEY: ""
    VLM_CAPTIONING_DEVICE: "CPU"
    LLM_CONCURRENT: "2"
    VLM_CONCURRENT: "4"
    SUMMARIZATION_MAX_COMPLETION_TOKENS: "4000"
    CAPTIONING_MAX_COMPLETION_TOKENS: "1024"
    LLM_MODEL_API: "v1/config"
    MULTI_FRAME_COUNT: "12"
    AUDIO_DEVICE: "cpu"
    OTLP_TRACE_URL: ""
    USE_OVMS: "CONFIG_OFF"
    SUMMARY_FEATURE: "FEATURE_ON"
    SEARCH_FEATURE: "FEATURE_OFF"
  nodeSelector: {}
  affinity: {}
  tolerations: []

audioanalyzer:
  enabled: false
  name: audioanalyzer
  service:
    port: 8000
    targetPort: 8000
    type: ClusterIP

videoingestion:
  enabled: false
  name: videoingestion
  fullnameOverride: videoingestion
  fullname: videoingestion
  # odModelName defines the name of Object Detection Model
  odModelName: ""
  # odModelType defines the type of Object Detection Model. e.g., 'yolo_v8'
  odModelType: ""
  service:
    type: ClusterIP
    port: 8080

ovms:
  name: ovms
  enabled: false
  service:
    port: 8300

vlminference:
  enabled: false
  name: vlm-inference-microservice

# Add nginx configuration
nginx:
  name: video-summary-nginx
  containerPortName: nginx-port 
  service:
    type: NodePort
    port: 80
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/ready
            operator: In
            values:
            - "true"

postgresql:
  name: postgresql
  fullname: postgresql
  service:
    type: ClusterIP
    port: 5432


# Placeholder for multimodal-embedding-ms subchart
multimodalembeddingms:
  enabled: false
  name: multimodal-embedding-ms
  textEmbeddingModel: ""
  imageEmbeddingModel: ""
  service:
    type: ClusterIP
    port: 8000

# Placeholder for vdms-dataprep subchart
vdmsdataprep:
  enabled: false
  name: vdms-dataprep
  service:
    type: ClusterIP
    port: 8000

# Placeholder for vdms-vectordb subchart
vdmsvectordb:
  enabled: false
  name: vdms-vectordb
  service:
    type: ClusterIP
    port: 55555

# Placeholder for videosearch subchart
videosearch:
  enabled: false
  name: videosearch
  service:
    type: ClusterIP
    port: 8000
